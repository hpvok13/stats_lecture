wandb: Currently logged in as: valmiki-kothare-vk. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.4
wandb: Run data is saved locally in /net/vast-storage.ib.cluster/scratch/user/valmiki/stats_lecture/wandb/run-20240410_015322-uy6irqk5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-snow-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/valmiki-kothare-vk/Price%20Predictor
wandb: üöÄ View run at https://wandb.ai/valmiki-kothare-vk/Price%20Predictor/runs/uy6irqk5
Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 0/67569 [00:00<?, ?it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 1/67569 [00:01<22:56:05,  1.22s/it]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 3/67569 [00:01<6:56:41,  2.70it/s] Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 5/67569 [00:01<4:02:41,  4.64it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 7/67569 [00:01<2:49:17,  6.65it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 9/67569 [00:01<2:11:51,  8.54it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 11/67569 [00:01<1:49:45, 10.26it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 13/67569 [00:01<1:35:36, 11.78it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 15/67569 [00:02<1:26:36, 13.00it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 17/67569 [00:02<1:20:31, 13.98it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 19/67569 [00:02<1:19:11, 14.22it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 21/67569 [00:02<1:17:59, 14.44it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 23/67569 [00:02<1:21:12, 13.86it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 25/67569 [00:02<1:38:08, 11.47it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 27/67569 [00:03<1:28:54, 12.66it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 29/67569 [00:03<1:40:10, 11.24it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 31/67569 [00:03<1:32:07, 12.22it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 33/67569 [00:03<1:25:50, 13.11it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 35/67569 [00:03<1:22:46, 13.60it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 37/67569 [00:03<1:34:01, 11.97it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 39/67569 [00:03<1:25:53, 13.10it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 41/67569 [00:04<1:31:09, 12.35it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 43/67569 [00:04<1:24:25, 13.33it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 45/67569 [00:04<1:35:53, 11.74it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 47/67569 [00:04<1:27:08, 12.91it/s]Training | Epoch: 0 | Loss: 0.0000 | Acc: 0.00%:   0%|          | 49/67569 [00:04<1:37:41, 11.52it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 49/67569 [00:04<1:37:41, 11.52it/s]  Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 51/67569 [00:04<1:29:58, 12.51it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 53/67569 [00:05<1:36:03, 11.71it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 55/67569 [00:05<1:27:15, 12.89it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 57/67569 [00:05<1:43:01, 10.92it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 59/67569 [00:05<1:33:59, 11.97it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 61/67569 [00:05<1:27:27, 12.87it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 63/67569 [00:05<1:25:37, 13.14it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 65/67569 [00:06<1:25:06, 13.22it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 67/67569 [00:06<1:21:27, 13.81it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 69/67569 [00:06<1:24:03, 13.38it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 71/67569 [00:06<1:18:58, 14.24it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 73/67569 [00:06<1:28:11, 12.76it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 75/67569 [00:06<1:22:51, 13.58it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 77/67569 [00:06<1:27:20, 12.88it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 79/67569 [00:07<1:21:57, 13.72it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 81/67569 [00:07<1:26:40, 12.98it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 83/67569 [00:07<1:24:14, 13.35it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 85/67569 [00:07<1:26:30, 13.00it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 87/67569 [00:07<1:23:07, 13.53it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 89/67569 [00:07<1:33:49, 11.99it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 91/67569 [00:08<1:26:40, 12.98it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 93/67569 [00:08<1:37:58, 11.48it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 95/67569 [00:08<1:28:47, 12.67it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 97/67569 [00:08<1:33:16, 12.06it/s]Training | Epoch: 0 | Loss: 300499947.0325 | :   0%|          | 99/67569 [00:08<1:25:38, 13.13it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 99/67569 [00:08<1:25:38, 13.13it/s] Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 101/67569 [00:08<1:38:44, 11.39it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 103/67569 [00:09<1:31:08, 12.34it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 105/67569 [00:09<1:31:47, 12.25it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 107/67569 [00:09<1:27:36, 12.83it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 109/67569 [00:09<1:31:34, 12.28it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 111/67569 [00:09<1:24:28, 13.31it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 113/67569 [00:09<1:36:39, 11.63it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 115/67569 [00:10<1:28:12, 12.74it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 117/67569 [00:10<1:30:08, 12.47it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 119/67569 [00:10<1:23:17, 13.50it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 121/67569 [00:10<1:33:12, 12.06it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 123/67569 [00:10<1:25:27, 13.15it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 125/67569 [00:10<1:35:08, 11.82it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 127/67569 [00:10<1:26:56, 12.93it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 129/67569 [00:11<1:36:43, 11.62it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 131/67569 [00:11<1:30:52, 12.37it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 133/67569 [00:11<1:31:04, 12.34it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 135/67569 [00:11<1:24:42, 13.27it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 137/67569 [00:11<1:32:10, 12.19it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 139/67569 [00:11<1:24:48, 13.25it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 141/67569 [00:12<1:31:28, 12.29it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 143/67569 [00:12<1:25:26, 13.15it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 145/67569 [00:12<1:38:18, 11.43it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 147/67569 [00:12<1:34:09, 11.93it/s]Training | Epoch: 0 | Loss: 16450825.6050 | :   0%|          | 149/67569 [00:12<1:29:25, 12.57it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 149/67569 [00:12<1:29:25, 12.57it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 151/67569 [00:12<1:27:05, 12.90it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 153/67569 [00:13<1:30:44, 12.38it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 155/67569 [00:13<1:23:44, 13.42it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 157/67569 [00:13<1:32:30, 12.14it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 159/67569 [00:13<1:24:44, 13.26it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 161/67569 [00:13<1:36:09, 11.68it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 163/67569 [00:13<1:27:23, 12.86it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 165/67569 [00:14<1:35:23, 11.78it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 167/67569 [00:14<1:27:02, 12.91it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 169/67569 [00:14<1:21:20, 13.81it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 171/67569 [00:14<1:19:56, 14.05it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 173/67569 [00:14<1:30:07, 12.46it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 175/67569 [00:14<1:23:28, 13.46it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 177/67569 [00:14<1:28:27, 12.70it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 179/67569 [00:15<1:22:19, 13.64it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 181/67569 [00:15<1:38:08, 11.44it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 183/67569 [00:15<1:31:02, 12.34it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 185/67569 [00:15<1:37:26, 11.52it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 187/67569 [00:15<1:34:40, 11.86it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 189/67569 [00:15<1:31:00, 12.34it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 191/67569 [00:16<1:25:14, 13.18it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 193/67569 [00:16<1:34:54, 11.83it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 195/67569 [00:16<1:28:21, 12.71it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 197/67569 [00:16<1:30:44, 12.37it/s]Training | Epoch: 0 | Loss: 14001172.8112 | :   0%|          | 199/67569 [00:16<1:24:41, 13.26it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 199/67569 [00:16<1:24:41, 13.26it/s] Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 201/67569 [00:16<1:32:38, 12.12it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 203/67569 [00:17<1:31:02, 12.33it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 205/67569 [00:17<1:26:44, 12.94it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 207/67569 [00:17<1:33:59, 11.94it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 209/67569 [00:17<1:25:58, 13.06it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 211/67569 [00:17<1:26:40, 12.95it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 213/67569 [00:17<1:27:27, 12.84it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 215/67569 [00:18<1:36:39, 11.61it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 217/67569 [00:18<1:27:51, 12.78it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 219/67569 [00:18<1:28:10, 12.73it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 221/67569 [00:18<1:33:20, 12.02it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 223/67569 [00:18<1:27:50, 12.78it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 225/67569 [00:18<1:27:41, 12.80it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 227/67569 [00:18<1:31:14, 12.30it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 229/67569 [00:19<1:28:30, 12.68it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 231/67569 [00:19<1:29:09, 12.59it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 233/67569 [00:19<1:22:37, 13.58it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 235/67569 [00:19<1:34:15, 11.91it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 237/67569 [00:19<1:28:44, 12.65it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 239/67569 [00:19<1:30:16, 12.43it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 241/67569 [00:20<1:24:25, 13.29it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 243/67569 [00:20<1:33:16, 12.03it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 245/67569 [00:20<1:31:35, 12.25it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 247/67569 [00:20<1:30:37, 12.38it/s]Training | Epoch: 0 | Loss: 7887213.8856 | :   0%|          | 249/67569 [00:20<1:24:23, 13.30it/s]Training | Epoch: 0 | Loss: 11291928.0569 | :   0%|          | 249/67569 [00:20<1:24:23, 13.30it/s]Training | Epoch: 0 | Loss: 11291928.0569 | :   0%|          | 251/67569 [00:20<1:40:26, 11.17it/s]Training | Epoch: 0 | Loss: 11291928.0569 | :   0%|          | 253/67569 [00:21<1:31:21, 12.28it/s]Training | Epoch: 0 | Loss: 11291928.0569 | :   0%|          | 255/67569 [00:21<1:36:01, 11.68it/s]Training | Epoch: 0 | Loss: 11291928.0569 | :   0%|          | 257/67569 [00:21<1:30:22, 12.41it/s]Training | Epoch: 0 | Loss: 11291928.0569 | :   0%|          | 259/67569 [00:21<1:37:58, 11.45it/s]Training | Epoch: 0 | Loss: 11291928.0569 | :   0%|          | 261/67569 [00:21<1:28:35, 12.66it/s]Training | Epoch: 0 | Loss: 11291928.0569 | :   0%|          | 261/67569 [00:21<1:33:31, 11.99it/s]
Traceback (most recent call last):
  File "/net/vast-storage.ib.cluster/scratch/user/valmiki/stats_lecture/src/price_predictor/train.py", line 233, in <module>
    train(config)
  File "/net/vast-storage.ib.cluster/scratch/user/valmiki/stats_lecture/src/price_predictor/train.py", line 182, in train
    train_loss, train_acc = train_epoch(
                            ^^^^^^^^^^^^
  File "/net/vast-storage.ib.cluster/scratch/user/valmiki/stats_lecture/src/price_predictor/train.py", line 35, in train_epoch
    for i, seq in enumerate(bar):
  File "/om2/user/valmiki/miniconda/envs/pytorch/lib/python3.11/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/om2/user/valmiki/miniconda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/om2/user/valmiki/miniconda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/valmiki/miniconda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/om2/user/valmiki/miniconda/envs/pytorch/lib/python3.11/site-packages/torch/_utils.py", line 722, in reraise
    raise exception
RuntimeError: Caught RuntimeError in DataLoader worker process 1.
Original Traceback (most recent call last):
  File "/om2/user/valmiki/miniconda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
           ^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/valmiki/miniconda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/valmiki/miniconda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py", line 277, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/valmiki/miniconda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py", line 121, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/om2/user/valmiki/miniconda/envs/pytorch/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py", line 173, in collate_tensor_fn
    out = elem.new(storage).resize_(len(batch), *list(elem.size()))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Trying to resize storage that is not resizable

wandb: - 0.016 MB of 0.027 MB uploaded (0.003 MB deduped)wandb: \ 0.027 MB of 0.027 MB uploaded (0.003 MB deduped)wandb: 
wandb: Run history:
wandb: running_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb: running_loss 11291928.05687
wandb: 
wandb: üöÄ View run silver-snow-2 at: https://wandb.ai/valmiki-kothare-vk/Price%20Predictor/runs/uy6irqk5
wandb: Ô∏è‚ö° View job at https://wandb.ai/valmiki-kothare-vk/Price%20Predictor/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE2MTAyNzQzOQ==/version_details/v1
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240410_015322-uy6irqk5/logs
